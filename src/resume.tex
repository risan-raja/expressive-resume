\documentclass{ExpressiveResume}

% ----- Resume -----
\begin{document}
\righthyphenmin=62
\lefthyphenmin=62

% ----- Name + Contact Information -----
\resumeheader[
	firstname=Risan Raja,
	% middleinitial= ,
	% lastname=Raja,
	email=risan.raja@icloud.com,
	linkedin=risanraja,
	github=risan-raja,
	phone=963-332-6718,
	% city=Town,
	% state=State,
	% qrcode=./images/qr.png
]

\section{Profile Summary}{
  \objective{Seeking a Research-Focused Machine Learning Engineer
	  position to utilize 4+ years of experience and a strong aptitude for
	  problem-solving in developing and implementing innovative solutions
	  within a dynamic and challenging environment.
  }
 }



% ----- Work Experience -----
\section{Work Experience}

\experience{Center for Computational Brain Research, IIT Madras}{%
	\role{ML and Computer Vision Researcher}{Jun 2024 - Mar 2025}{
		\achievement{
			Led the development of Automated Image Registration and Stacking for
			histopathological Images. Repurposed various \textbf{SOTA MRI} based
			registration pipelines for histopathological images by optimizing it
		to process large histopathological images (200GB+/image) using
		\textbf{deep learning based optimization(LDDM)} to improve the 
		registration accuracy by over \textbf{70\%} and
		sped up annotation speed by \textbf{3x}.
		}
		\achievement{
			Formulated a novel optimized pipeline for finding errors
			within the annotated anatomical structures by adopting the best
		practices from \textbf{geospatial data processing}. Reduced the time
		taken from \textbf{5 minutes to under 15 seconds}.
		}
		\achievement{
			\textcolor{black}{Developed an end to end ETL pipeline using \tech{\textcolor{black}{Dask and Pytorch}}} which leveraged the
		existing anatomical data stored in geospatial format to stream 	asynchronously
		\textbf{100K patches/s} of large histopathological for training 
		\textbf{GANs and Stable Diffusion networks} for image generation and segmentation.
		}
		\achievement{
		\textcolor{black}{ Augmented the development of \textbf{RAG
		based QA} system by reducing the latency of the ORM to query and interact with the
		knowledge base by \textbf{21\%}.}
		}
		\achievement{
			\textcolor{black}{Strategized and implemented inference serving using
				in house \textbf{DGX A100 cluster(5 Nodes)} using \textbf{NVIDIA Triton Inference
		Server}. \textbf{Apache Airflow} was used as the
		main orchestrator.}
		}
		\achievement{
			\textcolor{black}{Assisted in developing the in-house code
				suggestion tool using  \textbf{AST based syntax generation} for the
				research team using Mistral 70B. Supplemented it with subject
				based knowledge graph to enhance the code suggestion.
				Worked with the front end team to develop the chrome based
				plugin to be used in JupyterHub.}
		}
	}

}
\experience{IBG Consulting}{%
	\role{Machine Learning Engineer}{Aug 2020 - May 2024}{
		\achievement{
			Contributed to strategic decision-making by developing machine
			learning models leveraging \textbf{PyTorch and NIXTLA}.
			These models continuously analyzed commodity options and futures market trading
			patterns to assess the viability of sales and export demand in
			international markets relevant to the company's raw material
			procurement and improved the turn around time of the warehouse
			stock by \textbf{20\%}.
		}
		\achievement{
			Finetuned \textbf{T5-based LLM} using PEFT to eliminate jargon within
			the published analyst reports, in return enhancing the available corpus more streamlined for
			downstream tasks improving the pipeline efficiency by approx \textbf{30\%}.
		}
	}
}
% \experience{Coderstrust}{%
% 	\role{Digital Marketing Strategist}{2017}{
% 		% \achievement{
% 		% 	Strategized and executed a digital marketing campaigns in the
% 		% 	APAC region. Worked with the CMO and cofounder to develop a data
% 		% 	first approach to marketing by leveraging the data from the
% 		% 	company's LMS and CRM to develop a more targeted marketing  strategy.
% 		% }
% 	}
% }

% \experience{Nielsen Sports}{
% 	\role{Digital Analyst}{2016}{
% 		% 	\achievement{
% 		% Implemented a data pipeline to ingest data from multiple large
% 		% social media entities to seamlessly integrate with social media
% 		% valuation tools
% 		% 	}
% 		% 	\achievement{
% 		% Worked on NLP based sentiment analysis to gauge the sentiment from
% 		% the collected data and develop a more robust social media valuation algorithm.
% 		% 	}
% 	}
% }

% ----- Education -----
\section{Education}
\degree{B.S. Data Science and Programming}{IIT Madras}{2021-2024}{
	\achievement{
		TA for the course C Programming
	}
}
\degree{B.Sc Information Technology}{SMU}{2015-2018}{
}

% ----- Skills -----
\section{Skills}{
  % Languages: Python, JavaScript, C \\
  \role{Languages}{\normalfont Python, JavaScript, C}
  \role{Frameworks}
  {\normalfont TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning,
	  Git, Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark,
	  NIXTLA, JINA, TF Serving, NVIDIA Triton Inference Server}
  \role{Domains}{
	  \normalfont NLP, Non-Stationary Time Series Modeling, Computer Vision,
	  Computational Geometry, Image Registration, Non-Linear Optimization,
	  Bayesian Optimization
  }

 }

% Frameworks: TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning, Git,
% Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark


% ----- Awards -----
\section{Awards}

\award{1\textsuperscript{st} Place}{PixelMind AI Hackathon}{2023}{
	\achievement{Architected an AI Agent using \textbf{RL} by leveraging
	the MAXIM and SPLINET for automatically enhancing high-resolution 
	photography images.}
}
\award{3\textsuperscript{rd} Place}{DSA Challenge, IITM}{2023}{
}

\award{9\textsuperscript{th} Place}{WorldQuant Alpha Challenge}{2023}{
	\achievement{
		Developed Simulated Annealing based Genetic Algorithm which used the
		PnL generated by the Alpha as a heuristic. The automated alpha
		generation used \textbf{AST based alpha generation} to meet the competition
		requirements.The guided search algorithm refines the alpha by
		using \textbf{SGD} as one of its heuristics.
	}
}


% ----- Technical Projects -----
\section{Technical Projects}

\experience{Pointwise Temporal Fusion Transformer}{

	\achievement{
		Revamped the Temporal Fusion Transformer from scratch to support
		multi-horizon predictions in non-stationary financial datasets. 
		 Its key innovation is operating as a deep time index model for
		time series forecasting. Custom training loop was developed to 
		ingest the large training and utilized 8 A100 GPUs to train the
		model in 3 days. Finally outperforming the best
		solution published in the original kaggle challenge. Converted
		the project from \textbf{Tensorflow} to \textbf{Pytorch
			Lightning} to leverage DDP for distributed training.
		\href{https://github.com/risan-raja/jane_street}{\faIcon{github}}
	}

}

\experience{ONDC Indexing System}{

	\achievement{
		Fine tuned existing \textbf{JINA} LLM embedding model to
		semantically index
		indian categorical data for the ONDC project. The model was
		optimized to handle the large scale data and was deployed using
		Google Kubernetes Engine(GCP) and also Vertex AI endpoint using GRPC.
		It was also additionally optimized using attention layer fusion to optimize for large scale data.Additionally,
		created a custom Docker image for model serving using 
		NVIDIA Triton Inference Server.
		\href{https://docs.google.com/presentation/d/1ewra3_4lZK1NbzY-oZwZo324f43RKughmSyyBj6M20I/edit?usp=sharing}{\faIcon{link}}
	}

}

\experience{Sparse Embedding Transformer Model Optimization}{
	\achievement{
		Optimized the existing \textbf{NAVER SPLADE} model based on BERT to
		embed categorical information using max-pooling. Reused weights from a model which was trained on a
		contrastive learning task to further optimize the model. Main
		optimization objective was to keep the VRAM usage to a minimum.

		Engineered the model in two parts to handle both document and query
		embeddings to further optimize the model for the large scale data.
	}
}

\end{document}
