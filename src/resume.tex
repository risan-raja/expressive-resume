\documentclass{ExpressiveResume}

% ----- Resume -----
\begin{document}

% ----- Name + Contact Information -----
\resumeheader[
	firstname=Risan Raja,
	% middleinitial= ,
	% lastname=Raja,
	email=risan.raja@icloud.com,
	linkedin=risanraja,
	github=risan-raja,
	phone=963-332-6718,
	% city=Town,
	% state=State,
	% qrcode=./images/qr.png
]

\objective{Seeking a Research-Focused Machine Learning Engineer position to utilize 4+ years of experience and a strong aptitude for problem-solving in developing and implementing innovative solutions within a dynamic and challenging environment.}

% ----- Work Experience -----
\section{Work Experience}

\experience{Center for Computational Brain Research, IIT Madras}{%
	\role{ML and Computer Vision Researcher}{2024-2025}{
		\achievement{
			Developed Automated Image Registration and Stacking for
			Histological Images. Repurposed various \textbf{SOTA MRI} based
			registration pipelines for histological images by optimzing it
		to handle large histological images (200GB+/image) using GANS
		and VAEs.
		}
		\achievement{
			Developed a novel optimzed pipeline for finding errors
			within the annotated anatomical structures by adopting the best
			practices from geospatial data processing.
		}
		\achievement{
			\textcolor{black}{Implemented an end to end ETL pipeline using \tech{\textcolor{black}{Dask and Pytorch}}} which leveraged the
			existing anatomical data stored in geospatial format to stream asynchronusly
		\textbf{100K patches/s} of large histological for training the
		deep learning models(GANs and Stable Diffusion Models).
		}
		\achievement{
			\textcolor{black}{ Contributed to the development of \textbf{RAG based QA} system for Neuroscience based projects.}
		}
		\achievement{
		\textcolor{black}{Strategised and implemented model serving using
		in house DGX A100 cluster using \textbf{NVIDIA Triton Inference
		Server} for the developed models.}
		}
		\achievement{
			\textcolor{black}{Developed automated CI/CD pipeline to integrate with the frontend using Jenkins and Docker }
		}
		\achievement{
			\textcolor{black}{Contributed in deploying in-house code
				suggestion tool using \textbf{AST based code generation} for the
				research team using Mistral 7B. Supplemented it with subject
				based knowledge graph to further enhance the code suggestion.
				Worked with the front end team to develop the chrome based
				plugin  for the code suggestion tool.}
		}
	}

}
\experience{IBG Consulting}{%
	\role{Business Analyst}{2021-2024}{
		\achievement{
			Contributed to strategic decision-making by developing a machine
			learning model leveraging \textbf{PyTorch and NIXTLA}.
			This model analyzed commodity options and futures market trading
			patterns to assess the viability of sales and export demand in
			international markets relevant to the company's raw material
		procurement and improved the turn around time of the warehouse
		stock by 20\%.
		}
		\achievement{
			Fine Tuned \textbf{T5} based model using PEFT to eliminate jargon within
			the published analyst reports to make available corpus more streamlined for
		downstream tasks improving the pipeline efficiency by approx 30\%.
		}
	}
}
\experience{Coderstrust}{%
	\role{Digital Marketing Strategist}{2017}{
		% \achievement{
		% 	Strategized and executed a digital marketing campaigns in the
		% 	APAC region. Worked with the CMO and cofounder to develop a data
		% 	first approach to marketing by leveraging the data from the
		% 	company's LMS and CRM to develop a more targeted marketing  strategy.
		% }
	}
}

\experience{Nielsen Sports}{
	\role{Digital Analyst}{2016}{
		% 	\achievement{
		% Implemented a data pipeline to ingest data from multiple large
		% social media entities to seamlessly integrate with social media
		% valuation tools
		% 	}
		% 	\achievement{
		% Worked on NLP based sentiment analysis to gauge the sentiment from
		% the collected data and develop a more robust social media valuation algorithm.
		% 	}
	}
}
% ----- Awards -----
\section{Awards}

\award{First Place}{PixelMind AI Hackathon}{2023}{
	\achievement{Created an AI Agent using \textbf{RL} by leveraging the MAXIM and SPLINET for automatically enhancing high-resolution photgraphy images.}
}
\award{Third Place}{DSA Challenge, IITM}{2023}{
}

\award{9th Place}{WorldQuant Alpha Challenge}{2023}{
	\achievement{
		Developed Simulated Annealing based Genetic Algorithm which used the
		PnL generated by the Alpha as a heuristic. The automated alpha
		generation used AST based code generation to meet the competition
		requirements.The guided search algorithm further refines the alpha
		using \textbf{SGD} based optimization.
	}
}

% ----- Education -----
\section{Education}
\degree{B.S. Data Science and Programming}{IIT Madras}{2024}{
	\achievement{
		TA for the course C Programming
	}
}
\degree{BSc Information Technology}{SMU}{2018}{
}

% ----- Technical Projects -----
\section{Technical Projects}

\experience{Pointwise Temporal Fusion Transformer}{

	\achievement{
		Redesigned Temporal Fusion Transformer from ground up to handle
		multi horizon prediction in non-stationary financial data. The
		novelty is in the ability to perform like a deep time index
		model for time series forecasting tasks.
		Custom training loop was developed to handle the large training
		and utilized 8 A100 GPUs to train the model in 3 days. Finally
		outperforming the best solution published in the original kaggle
		challenge. Rewrote the code from \textbf{Tensorflow} to \textbf{Pytorch
			Lightning} to leverage FSDP for distributed training.
		\href{https://github.com/risan-raja/jane_street}{\faIcon{github}}
	}

}

\experience{ONDC Indexing System}{

	\achievement{
		Retrained existing \textbf{JINA} LLM embedding model to handle
		indian categorical data for the ONDC project. The model was
		optimized to handle the large scale data and was deployed using
		Google Kubernetes Engine(GCP) and also Vertex AI endpoint using GRPC.
		The model was also further optimized using attention
		layer fusion to optimize for large scale data. Further also
		created custom docker image to handle the model serving using
		NVIDIA Triton Inference Server.
		\href{https://docs.google.com/presentation/d/1ewra3_4lZK1NbzY-oZwZo324f43RKughmSyyBj6M20I/edit?usp=sharing}{\faIcon{link}}
	}

}

\experience{Sparse Embedding Transformer Model Optimization}{
	\achievement{
		Optimized the existing \textbf{NAVER SPLADE} model based on BERT to
		embed categorical information using max-pooling. Reused weights from a model which was trained on a
		contrastive learning task to further optimize the model. Main
		optimization objective was to keep the VRAM usage to a minimum.

		Engineered the model in two parts to handle both document and query
		embeddings to further optimize the model for the large scale data.
	}
}

% ----- Skills -----
\section{Skills}{
  % Languages: Python, JavaScript, C \\
  \role{Languages}{\normalfont Python, JavaScript, C}
  \role{Frameworks}
  {\normalfont TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning,
  Git, Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark,
  NIXTLA, JINA, TF Serving, NVIDIA Triton Inference Server}

 }
% Frameworks: TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning, Git,
% Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark

\end{document}