\documentclass{ExpressiveResume}

% ----- Resume -----
\begin{document}

% ----- Name + Contact Information -----
\resumeheader[
	firstname=Risan Raja,
	% middleinitial= ,
	% lastname=Raja,
	email=risan.raja@icloud.com,
	linkedin=risanraja,
	github=risan-raja,
	phone=963-332-6718,
	% city=Town,
	% state=State,
	% qrcode=./images/qr.png
]

\objective{Seeking a Research-Focused Machine Learning Engineer position to utilize 4+ years of experience and a strong aptitude for problem-solving in developing and implementing innovative solutions within a dynamic and challenging environment.}

% ----- Work Experience -----
\section{Work Experience}

\experience{Center for Computational Brain Research, IIT Madras}{%
	\role{ML and Computer Vision Research Intern}{2024-2025}{
		\achievement{
			Developed Automated Image Registration and Stacking for
			Histological Images. Repurposed various \textbf{SOTA MRI} based
			registration pipelines for histological images by optimzing it
			to handle large histological images (200GB+/image).
		}
		\achievement{
			Developed a novel optimzed pipeline for finding errors
			within the annotated anatomical structures by adopting the best
			practices from geospatial data processing.
		}
		\achievement{
			\textcolor{black}{Implemented an end to end ETL pipeline using \tech{\textcolor{black}{Dask and Pytorch}}} which leveraged the
			existing anatomical data stored in geospatial format to stream asynchronusly
			\textbf{100K patches/s} of large histological for training the deep learning models.
		}
		\achievement{
			\textcolor{black}{ Contributed to the development of \textbf{RAG based QA} system for Neuroscience based projects.}
		}
		\achievement{
			\textcolor{black}{Developed automated CI/CD pipeline to integrate with the frontend using Jenkins and Docker }
		}
	}

}
\experience{IBG Consulting}{%
	\role{Business Analyst}{2021-2024}{
		\achievement{
			Worked closely with the management to develop a machine learning
			model using \textbf{Pytorch and NIXTLA} based on the trading patterns of the commodities options and futures
			markets to model the viability of sales/export demand in various
			international markets for raw materials procured by the company.
		}
	}
}
\experience{Coderstrust}{%
	\role{Digital Marketing Strategist}{2017}{
		% \achievement{
		% 	Strategized and executed a digital marketing campaigns in the
		% 	APAC region. Worked with the CMO and cofounder to develop a data
		% 	first approach to marketing by leveraging the data from the
		% 	company's LMS and CRM to develop a more targeted marketing  strategy.
		% }
	}
}

\experience{Nielsen Sports}{
	\role{Digital Analyst}{2016}{
	% 	\achievement{
	% Implemented a data pipeline to ingest data from multiple large
	% social media entities to seamlessly integrate with social media
	% valuation tools
	% 	}
	% 	\achievement{
	% Worked on NLP based sentiment analysis to gauge the sentiment from
	% the collected data and develop a more robust social media valuation algorithm.
	% 	}
	}
}
% ----- Awards -----
\section{Awards}

\award{First Place}{PixelMind AI Hackathon}{2023}{
	\achievement{Created an AI Agent using \textbf{RL} by leveraging the MAXIM and SPLINET for automatically enhancing high-resolution photgraphy images.}
}
\award{Third Place}{DSA Challenge, IITM}{2023}{
}

\award{9th Place}{WorldQuant Alpha Challenge}{2023}{
	\achievement{
	Developed Simulated Annealing based Genetic Algorithm which used the
	PnL generated by the Alpha as a heuristic. The automated alpha
	generation used AST based code generation to meet the competition
	requirements.The guided search algorithm further refines the alpha
	using \textbf{SGD} based optimization.
	}
}

% ----- Education -----
\section{Education}
\degree{B.S. Data Science and Programming}{IIT Madras}{2024}{
}
\degree{BSc Information Technology}{SMU}{2018}{
}

% ----- Technical Projects -----
\section{Technical Projects}

\experience{Pointwise Temporal Fusion Transformer}{

	\achievement{
		Redesigned Temporal Fusion Transformer from ground up to handle
		multi horizon prediction in non-stationary financial data. The
		novelty is in the ability to perform like a deep time index
		model for time series forecasting tasks. 
		Custom training loop was developed to handle the large training
		and utilized 8 A100 GPUs to train the model in 3 days. Finally
		outperforming the best solution published in the original kaggle
		challenge. Rewrote the code from \textbf{Tensorflow} to \textbf{Pytorch
		Lightning} to leverage FSDP for distributed training. 
		\href{https://github.com/risan-raja/jane_street}{\faIcon{github}}
	}

}

\experience{ONDC Indexing System}{

	\achievement{
		Retrained existing \textbf{JINA} embedding model to handle
		indian categorical data for the ONDC project. The model was
		optimized to handle the large scale data and was deployed using
		Google Kubernetes Engine(GCP).
		The model was also further optimized using attention
		layer fusion to optimize for large scale data. Further also
		created custom docker image to handle the model serving using
		NVIDIA Triton Inference Server.
		\href{https://docs.google.com/presentation/d/1ewra3_4lZK1NbzY-oZwZo324f43RKughmSyyBj6M20I/edit?usp=sharing}{\faIcon{link}}
	}

}

\experience{Sparse Embedding Transformer Model Optimization}{
	\achievement{
		Optimized the existing \textbf{SET} model to handle the sparse
	embedding data. Reused weights from a model which was trained on a
	contrastive learning task to further optimize the model.

	Engineered the model in two parts to handle both document and query
	embeddings to further optimize the model for the large scale data.
	}
}
\section{Skills}{
% Languages: Python, JavaScript, C \\
\role{Languages}{\normalfont Python, JavaScript, C}
\role{Frameworks}
{\normalfont TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning, Git, Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark}

}
% Frameworks: TensorFlow, PyTorch, Scikit-learn, Pytorch Lightning, Git,
% Flask, Django, ONNX, GCP, AWS, Kubernetes, Docker, Dask, PySpark

\end{document}